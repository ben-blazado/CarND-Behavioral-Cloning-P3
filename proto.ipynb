{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "functioning-oliver",
   "metadata": {},
   "source": [
    "# Data Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "adolescent-norwegian",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "WARNING:root:Limited tf.compat.v2.summary API due to missing TensorBoard installation.\n"
     ]
    }
   ],
   "source": [
    "from math import ceil, floor\n",
    "from random import shuffle\n",
    "from keras.utils import Sequence\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import csv\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "jewish-essay",
   "metadata": {},
   "outputs": [],
   "source": [
    "def shift(img, dx):\n",
    "        \n",
    "    shifted_img = np.zeros_like(img)\n",
    "    if dx > 0:\n",
    "        # shift right\n",
    "        shifted_img[:,dx:] = img[:,:-dx]\n",
    "    else:\n",
    "        # shift left\n",
    "        shifted_img[:,:dx] = img[:,-dx:]\n",
    "\n",
    "    return shifted_img\n",
    "\n",
    "\n",
    "# ref: https://stanford.edu/~shervine/blog/keras-how-to-generate-data-on-the-fly\n",
    "class DrivingLogSequence(Sequence):\n",
    "    \n",
    "    def __init__ (self, driving_log, batch_size=32):\n",
    "        \n",
    "        self.driving_log = driving_log\n",
    "        self.batch_size = batch_size\n",
    "        \n",
    "        theta = 0.35\n",
    "        \n",
    "        self.cameras = [('center', 0), ('left', theta), ('right', -theta)]\n",
    "        \n",
    "        return\n",
    "    \n",
    "    def __len__(self):\n",
    "        return floor(len(self.driving_log)/self.batch_size)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        \n",
    "        batch_driving_log = self.driving_log[index:index+self.batch_size]\n",
    "        images = []\n",
    "        steerings = []\n",
    "        \n",
    "        for line in batch_driving_log:\n",
    "            \n",
    "            center_steering = float(line['steering'])\n",
    "            \n",
    "            for cam_pos, theta in self.cameras:\n",
    "                \n",
    "                filename = line[cam_pos].strip()\n",
    "                \n",
    "                img = plt.imread('sample_data/' + filename).copy()\n",
    "                img[:,159:162] = [255, 0, 0]                \n",
    "                images.append(img)\n",
    "                steering = center_steering + theta\n",
    "                steerings.append([steering])\n",
    "                \n",
    "                # augment with flipped image\n",
    "                flip_img = np.fliplr(img)\n",
    "                images.append(flip_img)\n",
    "                steerings.append([-steering])\n",
    "                \n",
    "                continue\n",
    "                \n",
    "                # augment with left shift\n",
    "                leftshift_img = shift(img, -75)\n",
    "                images.append(leftshift_img)\n",
    "                steerings.append([steering + 2*theta])\n",
    "                \n",
    "                # augment with right shift\n",
    "                rightshift_img = shift(img, 75)\n",
    "                images.append(rightshift_img)\n",
    "                steerings.append([steering - 2*theta])\n",
    "                \n",
    "            \n",
    "        X = np.array(images)\n",
    "        y = np.array(steerings)\n",
    "        \n",
    "        return X, y\n",
    "    \n",
    "    def on_epoch_end(self):\n",
    "        shuffle(self.driving_log)\n",
    "        return\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "instrumental-paste",
   "metadata": {},
   "outputs": [],
   "source": [
    "driving_log_filename = 'sample_data/driving_log.csv'\n",
    "\n",
    "driving_log = []\n",
    "\n",
    "with open(driving_log_filename) as driving_log_file:\n",
    "    driving_log_reader = csv.DictReader(driving_log_file)\n",
    "    for line in driving_log_reader:\n",
    "        driving_log.append(line)\n",
    "        \n",
    "driving_log_training, driving_log_validation = train_test_split(driving_log, test_size=0.2)\n",
    "driving_log_seq_training   = DrivingLogSequence(driving_log_training)\n",
    "driving_log_seq_validation = DrivingLogSequence(driving_log_validation)        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "scientific-recall",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "limiting-argentina",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "image_name = \"sample_data/IMG/left_2016_12_01_13_30_48_287.jpg\"\n",
    "img=plt.imread(\"sample_data/IMG/left_2016_12_01_13_30_48_287.jpg\")\n",
    "img_copy = np.copy(img)\n",
    "img_copy[:,159:162] = [255, 0, 0]\n",
    "\n",
    "plt.imshow(img_copy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "applied-strike",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def shift(img, dx):\n",
    "\n",
    "    shifted_img = np.zeros_like(img)\n",
    "    if dx > 0:\n",
    "        # shift right\n",
    "        shifted_img[:,dx:] = img[:,:-dx]\n",
    "    else:\n",
    "        # shift left\n",
    "        shifted_img[:,:dx] = img[:,-dx:]\n",
    "\n",
    "    return shifted_img\n",
    "\n",
    "shift_img = shift(img, -75)\n",
    "plt.imshow(shift_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "terminal-glenn",
   "metadata": {},
   "outputs": [],
   "source": [
    "img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "prostate-quest",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import numpy as np\n",
    "\n",
    "driving_log_filename = 'sample_data/driving_log.csv'\n",
    "\n",
    "center_images = []\n",
    "steerings = []\n",
    "with open(driving_log_filename) as driving_log:\n",
    "    driving_log_reader = csv.DictReader(driving_log)\n",
    "    for row in driving_log_reader:\n",
    "        center_images.append(plt.imread('sample_data/' + row['center']))\n",
    "        steerings.append([float(row['steering'])])\n",
    "                            \n",
    "X_train = np.array(center_images)\n",
    "y_train = np.array(steerings)\n",
    "    \n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "civil-civilization",
   "metadata": {},
   "outputs": [],
   "source": [
    "# adding left and right cameras\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import csv\n",
    "import numpy as np\n",
    "\n",
    "driving_log_filename = 'sample_data/driving_log.csv'\n",
    "\n",
    "images = []\n",
    "steerings = []\n",
    "theta = 0.35\n",
    "with open(driving_log_filename) as driving_log:\n",
    "    driving_log_reader = csv.DictReader(driving_log)\n",
    "    for row in driving_log_reader:\n",
    "        \n",
    "        steering = float(row['steering'])\n",
    "        \n",
    "        images.append(plt.imread('sample_data/' + row['center'].strip()))\n",
    "        steerings.append([steering])\n",
    "        \n",
    "        images.append(plt.imread('sample_data/' + row['left'].strip()))\n",
    "        steerings.append([steering + theta])\n",
    "        \n",
    "        images.append(plt.imread('sample_data/' + row['right'].strip()))\n",
    "        steerings.append([steering - theta])\n",
    "        \n",
    "                            \n",
    "X_train = np.array(images)\n",
    "y_train = np.array(steerings)\n",
    "    \n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "latter-gospel",
   "metadata": {},
   "outputs": [],
   "source": [
    " \n",
    "'''\n",
    "def generator(lines, batch_size=32):\n",
    "\n",
    "    driving_log_filename = 'sample_data/driving_log.csv'\n",
    "\n",
    "    images = []\n",
    "    steerings = []\n",
    "    theta = 0.35\n",
    "    \n",
    "    with open(driving_log_filename) as driving_log:\n",
    "        num_lines = 0\n",
    "        for line in driving_log:\n",
    "            num_lines += 1\n",
    "\n",
    "    with open(driving_log_filename) as driving_log:\n",
    "\n",
    "        driving_log_reader = csv.DictReader(driving_log)\n",
    "        \n",
    "        \n",
    "        print (len(driving_log_reader))\n",
    "\n",
    "    for row in driving_log_reader:\n",
    "\n",
    "        steering = float(row['steering'])\n",
    "\n",
    "        images.append(plt.imread('sample_data/' + row['center'].strip()))\n",
    "        steerings.append([steering])\n",
    "\n",
    "        images.append(plt.imread('sample_data/' + row['left'].strip()))\n",
    "        steerings.append([steering + theta])\n",
    "\n",
    "        images.append(plt.imread('sample_data/' + row['right'].strip()))\n",
    "        steerings.append([steering - theta])\n",
    "    '''\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "intelligent-difficulty",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(X_train[45])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "material-effects",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train[46]\n",
    "\n",
    "for y in y_train:\n",
    "    if y > 0:\n",
    "        print(y)\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "optimum-haiti",
   "metadata": {},
   "source": [
    "## Network Structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "innocent-casting",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Owner\\anaconda3\\envs\\bcl\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:64: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Owner\\anaconda3\\envs\\bcl\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:64: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Owner\\anaconda3\\envs\\bcl\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:497: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Owner\\anaconda3\\envs\\bcl\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:497: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Owner\\anaconda3\\envs\\bcl\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3636: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Owner\\anaconda3\\envs\\bcl\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3636: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Owner\\anaconda3\\envs\\bcl\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:1264: calling reduce_prod_v1 (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Owner\\anaconda3\\envs\\bcl\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:1264: calling reduce_prod_v1 (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Lambda, Flatten, Dense, Conv2D, Cropping2D\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "def normalize(rgb):\n",
    "    '''\n",
    "    normalize rgb between [-1, 1]\n",
    "    '''\n",
    "    \n",
    "    return (rgb-128.0) / 128.0\n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Lambda(normalize, input_shape=(160,320,3)))\n",
    "model.add(Cropping2D(cropping=[(50, 20), (0, 0)]))\n",
    "model.add(Conv2D(filters=24, kernel_size=5, strides=2))\n",
    "model.add(Conv2D(filters=36, kernel_size=5, strides=2))\n",
    "model.add(Conv2D(filters=48, kernel_size=5, strides=2))\n",
    "model.add(Conv2D(filters=64, kernel_size=3, strides=2))\n",
    "model.add(Conv2D(filters=64, kernel_size=3, strides=2))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(100))\n",
    "model.add(Dense(50))\n",
    "model.add(Dense(10))\n",
    "model.add(Dense(1))\n",
    "          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "amber-cattle",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lambda_1 (Lambda)            (None, 160, 320, 3)       0         \n",
      "_________________________________________________________________\n",
      "cropping2d_1 (Cropping2D)    (None, 90, 320, 3)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 43, 158, 24)       1824      \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 20, 77, 36)        21636     \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 8, 37, 48)         43248     \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 3, 18, 64)         27712     \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 1, 8, 64)          36928     \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 100)               51300     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 50)                5050      \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 10)                510       \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 188,219\n",
      "Trainable params: 188,219\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "comparable-public",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Owner\\anaconda3\\envs\\bcl\\lib\\site-packages\\keras\\optimizers.py:711: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Owner\\anaconda3\\envs\\bcl\\lib\\site-packages\\keras\\optimizers.py:711: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam()\n",
    "model.compile(loss=tf.keras.losses.MSE, optimizer='Adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "close-thong",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Owner\\anaconda3\\envs\\bcl\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:958: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Owner\\anaconda3\\envs\\bcl\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:958: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Owner\\anaconda3\\envs\\bcl\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:680: calling Constant.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Owner\\anaconda3\\envs\\bcl\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:680: calling Constant.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Owner\\anaconda3\\envs\\bcl\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:945: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Owner\\anaconda3\\envs\\bcl\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:945: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Owner\\anaconda3\\envs\\bcl\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:2378: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Owner\\anaconda3\\envs\\bcl\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:2378: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "WARNING:tensorflow:From C:\\Users\\Owner\\anaconda3\\envs\\bcl\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:159: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Owner\\anaconda3\\envs\\bcl\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:159: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Owner\\anaconda3\\envs\\bcl\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:164: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Owner\\anaconda3\\envs\\bcl\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:164: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Owner\\anaconda3\\envs\\bcl\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:173: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Owner\\anaconda3\\envs\\bcl\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:173: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Owner\\anaconda3\\envs\\bcl\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:182: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Owner\\anaconda3\\envs\\bcl\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:182: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Owner\\anaconda3\\envs\\bcl\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:189: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Owner\\anaconda3\\envs\\bcl\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:189: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200/200 [==============================] - 33s 164ms/step - loss: 0.0422 - val_loss: 0.0754\n",
      "Epoch 2/10\n",
      "200/200 [==============================] - 30s 149ms/step - loss: 0.0121 - val_loss: 0.0700\n",
      "Epoch 3/10\n",
      "200/200 [==============================] - 29s 146ms/step - loss: 0.0103 - val_loss: 0.0727\n",
      "Epoch 4/10\n",
      "200/200 [==============================] - 27s 137ms/step - loss: 0.0091 - val_loss: 0.0892\n",
      "Epoch 5/10\n",
      "200/200 [==============================] - 29s 146ms/step - loss: 0.0086 - val_loss: 0.0864\n",
      "Epoch 6/10\n",
      "200/200 [==============================] - 28s 138ms/step - loss: 0.0101 - val_loss: 0.0694\n",
      "Epoch 7/10\n",
      "200/200 [==============================] - 28s 141ms/step - loss: 0.0084 - val_loss: 0.0718\n",
      "Epoch 8/10\n",
      "200/200 [==============================] - 27s 135ms/step - loss: 0.0077 - val_loss: 0.0626\n",
      "Epoch 9/10\n",
      "200/200 [==============================] - 28s 139ms/step - loss: 0.0080 - val_loss: 0.0676\n",
      "Epoch 10/10\n",
      "200/200 [==============================] - 27s 136ms/step - loss: 0.0075 - val_loss: 0.0727\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x21576dcf898>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit_generator(driving_log_seq_training, \n",
    "                    validation_data=driving_log_seq_validation, \n",
    "                    epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "possible-island",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X_train, y_train, batch_size=512, initial_epoch=0, epochs=4, shuffle=True, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "chronic-berry",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "every-bicycle",
   "metadata": {},
   "source": [
    "# drive.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "minute-balance",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import base64\n",
    "from datetime import datetime\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "import numpy as np\n",
    "import socketio\n",
    "import eventlet\n",
    "import eventlet.wsgi\n",
    "from PIL import Image\n",
    "from flask import Flask\n",
    "from io import BytesIO\n",
    "\n",
    "from keras.models import load_model\n",
    "import h5py\n",
    "from keras import __version__ as keras_version\n",
    "\n",
    "sio = socketio.Server()\n",
    "app = Flask(__name__)\n",
    "model = None\n",
    "prev_image_array = None\n",
    "\n",
    "\n",
    "class SimplePIController:\n",
    "    def __init__(self, Kp, Ki):\n",
    "        self.Kp = Kp\n",
    "        self.Ki = Ki\n",
    "        self.set_point = 0.\n",
    "        self.error = 0.\n",
    "        self.integral = 0.\n",
    "\n",
    "    def set_desired(self, desired):\n",
    "        self.set_point = desired\n",
    "\n",
    "    def update(self, measurement):\n",
    "        # proportional error\n",
    "        self.error = self.set_point - measurement\n",
    "\n",
    "        # integral error\n",
    "        self.integral += self.error\n",
    "\n",
    "        return self.Kp * self.error + self.Ki * self.integral\n",
    "\n",
    "\n",
    "controller = SimplePIController(0.1, 0.002)\n",
    "set_speed = 9\n",
    "controller.set_desired(set_speed)\n",
    "\n",
    "\n",
    "@sio.on('telemetry')\n",
    "def telemetry(sid, data):\n",
    "    if data:\n",
    "        # The current steering angle of the car\n",
    "        steering_angle = data[\"steering_angle\"]\n",
    "        # The current throttle of the car\n",
    "        throttle = data[\"throttle\"]\n",
    "        # The current speed of the car\n",
    "        speed = data[\"speed\"]\n",
    "        # The current image from the center camera of the car\n",
    "        imgString = data[\"image\"]\n",
    "        image = Image.open(BytesIO(base64.b64decode(imgString)))\n",
    "        image_array = np.asarray(image).copy()\n",
    "        image_array[:,159:162] = [255, 0, 0]                \n",
    "        steering_angle = float(model.predict(image_array[None, :, :, :], batch_size=1))\n",
    "\n",
    "        throttle = controller.update(float(speed))\n",
    "\n",
    "        print(steering_angle, throttle)\n",
    "        send_control(steering_angle, throttle)\n",
    "\n",
    "        # save frame\n",
    "        if args.image_folder != '':\n",
    "            timestamp = datetime.utcnow().strftime('%Y_%m_%d_%H_%M_%S_%f')[:-3]\n",
    "            image_filename = os.path.join(args.image_folder, timestamp)\n",
    "            image.save('{}.jpg'.format(image_filename))\n",
    "    else:\n",
    "        # NOTE: DON'T EDIT THIS.\n",
    "        sio.emit('manual', data={}, skip_sid=True)\n",
    "\n",
    "\n",
    "@sio.on('connect')\n",
    "def connect(sid, environ):\n",
    "    print(\"connect \", sid)\n",
    "    send_control(0, 0)\n",
    "\n",
    "\n",
    "def send_control(steering_angle, throttle):\n",
    "    sio.emit(\n",
    "        \"steer\",\n",
    "        data={\n",
    "            'steering_angle': steering_angle.__str__(),\n",
    "            'throttle': throttle.__str__()\n",
    "        },\n",
    "        skip_sid=True)\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    parser = argparse.ArgumentParser(description='Remote Driving')\n",
    "    parser.add_argument(\n",
    "        'model',\n",
    "        type=str,\n",
    "        help='Path to model h5 file. Model should be on the same path.'\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        'image_folder',\n",
    "        type=str,\n",
    "        nargs='?',\n",
    "        default='',\n",
    "        help='Path to image folder. This is where the images from the run will be saved.'\n",
    "    )\n",
    "    #parser.parse_args()    \n",
    "    #parser.parse_args(['--sum', '7', '-1', '42'])    \n",
    "    args = parser.parse_args(['model.h5'])\n",
    "\n",
    "    # check that model Keras version is same as local Keras version\n",
    "    f = h5py.File(args.model, mode='r')\n",
    "    model_version = f.attrs.get('keras_version')\n",
    "    keras_version = str(keras_version).encode('utf8')\n",
    "\n",
    "    if model_version != keras_version:\n",
    "        print('You are using Keras version ', keras_version,\n",
    "              ', but the model was built using ', model_version)\n",
    "\n",
    "    #mine\n",
    "    print(args.model)\n",
    "    model = load_model(args.model)\n",
    "\n",
    "    if args.image_folder != '':\n",
    "        print(\"Creating image folder at {}\".format(args.image_folder))\n",
    "        if not os.path.exists(args.image_folder):\n",
    "            os.makedirs(args.image_folder)\n",
    "        else:\n",
    "            shutil.rmtree(args.image_folder)\n",
    "            os.makedirs(args.image_folder)\n",
    "        print(\"RECORDING THIS RUN ...\")\n",
    "    else:\n",
    "        print(\"NOT RECORDING THIS RUN ...\")\n",
    "\n",
    "    # wrap Flask application with engineio's middleware\n",
    "    app = socketio.Middleware(sio, app)\n",
    "\n",
    "    # deploy as an eventlet WSGI server\n",
    "    eventlet.wsgi.server(eventlet.listen(('', 4567)), app)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "descending-milwaukee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "print(sys.version)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "wrapped-strike",
   "metadata": {},
   "outputs": [],
   "source": [
    "import socketio"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:bcl] *",
   "language": "python",
   "name": "conda-env-bcl-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
