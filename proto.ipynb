{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "limiting-argentina",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "image_name = \"sample_data/IMG/left_2016_12_01_13_30_48_287.jpg\"\n",
    "img=plt.imread(\"sample_data/IMG/left_2016_12_01_13_30_48_287.jpg\")\n",
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "terminal-glenn",
   "metadata": {},
   "outputs": [],
   "source": [
    "img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "prostate-quest",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import numpy as np\n",
    "\n",
    "driving_log_filename = 'sample_data/driving_log.csv'\n",
    "\n",
    "center_images = []\n",
    "steerings = []\n",
    "with open(driving_log_filename) as driving_log:\n",
    "    driving_log_reader = csv.DictReader(driving_log)\n",
    "    for row in driving_log_reader:\n",
    "        center_images.append(plt.imread('sample_data/' + row['center']))\n",
    "        steerings.append([float(row['steering'])])\n",
    "                            \n",
    "X_train = np.array(center_images)\n",
    "y_train = np.array(steerings)\n",
    "    \n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "civil-civilization",
   "metadata": {},
   "outputs": [],
   "source": [
    "# adding left and right cameras\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import csv\n",
    "import numpy as np\n",
    "\n",
    "driving_log_filename = 'sample_data/driving_log.csv'\n",
    "\n",
    "images = []\n",
    "steerings = []\n",
    "theta = 0.35\n",
    "with open(driving_log_filename) as driving_log:\n",
    "    driving_log_reader = csv.DictReader(driving_log)\n",
    "    for row in driving_log_reader:\n",
    "        \n",
    "        steering = float(row['steering'])\n",
    "        \n",
    "        images.append(plt.imread('sample_data/' + row['center'].strip()))\n",
    "        steerings.append([steering])\n",
    "        \n",
    "        images.append(plt.imread('sample_data/' + row['left'].strip()))\n",
    "        steerings.append([steering + theta])\n",
    "        \n",
    "        images.append(plt.imread('sample_data/' + row['right'].strip()))\n",
    "        steerings.append([steering - theta])\n",
    "        \n",
    "                            \n",
    "X_train = np.array(images)\n",
    "y_train = np.array(steerings)\n",
    "    \n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "instrumental-paste",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " IMG/left_2016_12_01_13_30_48_287.jpg\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import csv\n",
    "import numpy as np\n",
    "\n",
    "driving_log_filename = 'sample_data/driving_log.csv'\n",
    "\n",
    "driving_log = []\n",
    "\n",
    "with open(driving_log_filename) as driving_log_file:\n",
    "    driving_log_reader = csv.DictReader(driving_log_file)\n",
    "    for line in driving_log_reader:\n",
    "        driving_log.append(line)\n",
    "        \n",
    "        \n",
    "row = driving_log[0]\n",
    "print (row['left'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "jewish-essay",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "from math import ceil, floor\n",
    "from random import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.utils import Sequence\n",
    "\n",
    "\n",
    "# ref: https://stanford.edu/~shervine/blog/keras-how-to-generate-data-on-the-fly\n",
    "class DrivingLogSequence(Sequence):\n",
    "    \n",
    "    def __init__ (self, driving_log, batch_size=32):\n",
    "        \n",
    "        self.driving_log = driving_log\n",
    "        self.batch_size = batch_size\n",
    "        \n",
    "        self.theta = 0.35\n",
    "        \n",
    "        return\n",
    "    \n",
    "    def __len__(self):\n",
    "        return floor(len(self.driving_log)/self.batch_size)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        \n",
    "        batch_driving_log = self.driving_log[index:index+self.batch_size]\n",
    "        images = []\n",
    "        steerings = []\n",
    "        theta = 0.35\n",
    "        \n",
    "        for line in batch_driving_log:\n",
    "            \n",
    "            steering = float(line['steering'])\n",
    "\n",
    "            images.append(plt.imread('sample_data/' + line['center'].strip()))\n",
    "            steerings.append([steering])\n",
    "\n",
    "            images.append(plt.imread('sample_data/' + line['left'].strip()))\n",
    "            steerings.append([steering + theta])\n",
    "\n",
    "            images.append(plt.imread('sample_data/' + line['right'].strip()))\n",
    "            steerings.append([steering - theta])\n",
    "            \n",
    "        X = np.array(images)\n",
    "        y = np.array(steerings)\n",
    "        \n",
    "        return X, y\n",
    "    \n",
    "    def on_epoch_end(self):\n",
    "        shuffle(self.driving_log)\n",
    "        return\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "scientific-recall",
   "metadata": {},
   "outputs": [],
   "source": [
    "driving_log_training, driving_log_validation = train_test_split(driving_log, test_size=0.2)\n",
    "driving_log_seq_training   = DrivingLogSequence(driving_log_training)\n",
    "driving_log_seq_validation = DrivingLogSequence(driving_log_validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "latter-gospel",
   "metadata": {},
   "outputs": [],
   "source": [
    " \n",
    "'''\n",
    "def generator(lines, batch_size=32):\n",
    "\n",
    "    driving_log_filename = 'sample_data/driving_log.csv'\n",
    "\n",
    "    images = []\n",
    "    steerings = []\n",
    "    theta = 0.35\n",
    "    \n",
    "    with open(driving_log_filename) as driving_log:\n",
    "        num_lines = 0\n",
    "        for line in driving_log:\n",
    "            num_lines += 1\n",
    "\n",
    "    with open(driving_log_filename) as driving_log:\n",
    "\n",
    "        driving_log_reader = csv.DictReader(driving_log)\n",
    "        \n",
    "        \n",
    "        print (len(driving_log_reader))\n",
    "\n",
    "    for row in driving_log_reader:\n",
    "\n",
    "        steering = float(row['steering'])\n",
    "\n",
    "        images.append(plt.imread('sample_data/' + row['center'].strip()))\n",
    "        steerings.append([steering])\n",
    "\n",
    "        images.append(plt.imread('sample_data/' + row['left'].strip()))\n",
    "        steerings.append([steering + theta])\n",
    "\n",
    "        images.append(plt.imread('sample_data/' + row['right'].strip()))\n",
    "        steerings.append([steering - theta])\n",
    "    '''\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "intelligent-difficulty",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(X_train[45])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "material-effects",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train[46]\n",
    "\n",
    "for y in y_train:\n",
    "    if y > 0:\n",
    "        print(y)\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "optimum-haiti",
   "metadata": {},
   "source": [
    "## Network Structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "innocent-casting",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Lambda, Flatten, Dense, Conv2D, Cropping2D\n",
    "\n",
    "\n",
    "def normalize(rgb):\n",
    "    '''\n",
    "    normalize rgb between [-1, 1]\n",
    "    '''\n",
    "    \n",
    "    return (rgb-128.0) / 128.0\n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Lambda(normalize, input_shape=(160,320,3)))\n",
    "model.add(Cropping2D(cropping=[(50, 20), (0, 0)]))\n",
    "model.add(Conv2D(filters=24, kernel_size=5, strides=2))\n",
    "model.add(Conv2D(filters=36, kernel_size=5, strides=2))\n",
    "model.add(Conv2D(filters=48, kernel_size=5, strides=2))\n",
    "model.add(Conv2D(filters=64, kernel_size=3, strides=2))\n",
    "model.add(Conv2D(filters=64, kernel_size=3, strides=2))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(100))\n",
    "model.add(Dense(50))\n",
    "model.add(Dense(10))\n",
    "model.add(Dense(1))\n",
    "          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "amber-cattle",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lambda_3 (Lambda)            (None, 160, 320, 3)       0         \n",
      "_________________________________________________________________\n",
      "cropping2d_3 (Cropping2D)    (None, 90, 320, 3)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_11 (Conv2D)           (None, 43, 158, 24)       1824      \n",
      "_________________________________________________________________\n",
      "conv2d_12 (Conv2D)           (None, 20, 77, 36)        21636     \n",
      "_________________________________________________________________\n",
      "conv2d_13 (Conv2D)           (None, 8, 37, 48)         43248     \n",
      "_________________________________________________________________\n",
      "conv2d_14 (Conv2D)           (None, 3, 18, 64)         27712     \n",
      "_________________________________________________________________\n",
      "conv2d_15 (Conv2D)           (None, 1, 8, 64)          36928     \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 100)               51300     \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 50)                5050      \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 10)                510       \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 188,219\n",
      "Trainable params: 188,219\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "comparable-public",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam()\n",
    "model.compile(loss=tf.keras.losses.MSE, optimizer='Adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "close-thong",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "200/200 [==============================] - 21s 107ms/step - loss: 0.0071 - val_loss: 0.0558\n",
      "Epoch 2/3\n",
      "200/200 [==============================] - 20s 102ms/step - loss: 0.0058 - val_loss: 0.0577\n",
      "Epoch 3/3\n",
      "200/200 [==============================] - 21s 106ms/step - loss: 0.0069 - val_loss: 0.0510\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x17cd0e95f98>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit_generator(driving_log_seq_training, \n",
    "                    validation_data=driving_log_seq_validation, \n",
    "                    epochs=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "possible-island",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X_train, y_train, batch_size=512, initial_epoch=0, epochs=4, shuffle=True, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "chronic-berry",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "every-bicycle",
   "metadata": {},
   "source": [
    "# drive.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "minute-balance",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import base64\n",
    "from datetime import datetime\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "import numpy as np\n",
    "import socketio\n",
    "import eventlet\n",
    "import eventlet.wsgi\n",
    "from PIL import Image\n",
    "from flask import Flask\n",
    "from io import BytesIO\n",
    "\n",
    "from keras.models import load_model\n",
    "import h5py\n",
    "from keras import __version__ as keras_version\n",
    "\n",
    "sio = socketio.Server()\n",
    "app = Flask(__name__)\n",
    "model = None\n",
    "prev_image_array = None\n",
    "\n",
    "\n",
    "class SimplePIController:\n",
    "    def __init__(self, Kp, Ki):\n",
    "        self.Kp = Kp\n",
    "        self.Ki = Ki\n",
    "        self.set_point = 0.\n",
    "        self.error = 0.\n",
    "        self.integral = 0.\n",
    "\n",
    "    def set_desired(self, desired):\n",
    "        self.set_point = desired\n",
    "\n",
    "    def update(self, measurement):\n",
    "        # proportional error\n",
    "        self.error = self.set_point - measurement\n",
    "\n",
    "        # integral error\n",
    "        self.integral += self.error\n",
    "\n",
    "        return self.Kp * self.error + self.Ki * self.integral\n",
    "\n",
    "\n",
    "controller = SimplePIController(0.1, 0.002)\n",
    "set_speed = 9\n",
    "controller.set_desired(set_speed)\n",
    "\n",
    "\n",
    "@sio.on('telemetry')\n",
    "def telemetry(sid, data):\n",
    "    if data:\n",
    "        # The current steering angle of the car\n",
    "        steering_angle = data[\"steering_angle\"]\n",
    "        # The current throttle of the car\n",
    "        throttle = data[\"throttle\"]\n",
    "        # The current speed of the car\n",
    "        speed = data[\"speed\"]\n",
    "        # The current image from the center camera of the car\n",
    "        imgString = data[\"image\"]\n",
    "        image = Image.open(BytesIO(base64.b64decode(imgString)))\n",
    "        image_array = np.asarray(image)\n",
    "        steering_angle = float(model.predict(image_array[None, :, :, :], batch_size=1))\n",
    "\n",
    "        throttle = controller.update(float(speed))\n",
    "\n",
    "        print(steering_angle, throttle)\n",
    "        send_control(steering_angle, throttle)\n",
    "\n",
    "        # save frame\n",
    "        if args.image_folder != '':\n",
    "            timestamp = datetime.utcnow().strftime('%Y_%m_%d_%H_%M_%S_%f')[:-3]\n",
    "            image_filename = os.path.join(args.image_folder, timestamp)\n",
    "            image.save('{}.jpg'.format(image_filename))\n",
    "    else:\n",
    "        # NOTE: DON'T EDIT THIS.\n",
    "        sio.emit('manual', data={}, skip_sid=True)\n",
    "\n",
    "\n",
    "@sio.on('connect')\n",
    "def connect(sid, environ):\n",
    "    print(\"connect \", sid)\n",
    "    send_control(0, 0)\n",
    "\n",
    "\n",
    "def send_control(steering_angle, throttle):\n",
    "    sio.emit(\n",
    "        \"steer\",\n",
    "        data={\n",
    "            'steering_angle': steering_angle.__str__(),\n",
    "            'throttle': throttle.__str__()\n",
    "        },\n",
    "        skip_sid=True)\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    parser = argparse.ArgumentParser(description='Remote Driving')\n",
    "    parser.add_argument(\n",
    "        'model',\n",
    "        type=str,\n",
    "        help='Path to model h5 file. Model should be on the same path.'\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        'image_folder',\n",
    "        type=str,\n",
    "        nargs='?',\n",
    "        default='',\n",
    "        help='Path to image folder. This is where the images from the run will be saved.'\n",
    "    )\n",
    "    #parser.parse_args()    \n",
    "    #parser.parse_args(['--sum', '7', '-1', '42'])    \n",
    "    args = parser.parse_args(['model.h5'])\n",
    "\n",
    "    # check that model Keras version is same as local Keras version\n",
    "    f = h5py.File(args.model, mode='r')\n",
    "    model_version = f.attrs.get('keras_version')\n",
    "    keras_version = str(keras_version).encode('utf8')\n",
    "\n",
    "    if model_version != keras_version:\n",
    "        print('You are using Keras version ', keras_version,\n",
    "              ', but the model was built using ', model_version)\n",
    "\n",
    "    #mine\n",
    "    print(args.model)\n",
    "    model = load_model(args.model)\n",
    "\n",
    "    if args.image_folder != '':\n",
    "        print(\"Creating image folder at {}\".format(args.image_folder))\n",
    "        if not os.path.exists(args.image_folder):\n",
    "            os.makedirs(args.image_folder)\n",
    "        else:\n",
    "            shutil.rmtree(args.image_folder)\n",
    "            os.makedirs(args.image_folder)\n",
    "        print(\"RECORDING THIS RUN ...\")\n",
    "    else:\n",
    "        print(\"NOT RECORDING THIS RUN ...\")\n",
    "\n",
    "    # wrap Flask application with engineio's middleware\n",
    "    app = socketio.Middleware(sio, app)\n",
    "\n",
    "    # deploy as an eventlet WSGI server\n",
    "    eventlet.wsgi.server(eventlet.listen(('', 4567)), app)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "descending-milwaukee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "print(sys.version)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "wrapped-strike",
   "metadata": {},
   "outputs": [],
   "source": [
    "import socketio"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:bcl] *",
   "language": "python",
   "name": "conda-env-bcl-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
